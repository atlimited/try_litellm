#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import base64
import argparse
from typing import List, Dict, Any, Optional
import requests
from PIL import Image
import io
import time
from openai import OpenAI

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

# LiteLLMãƒ—ãƒ­ã‚­ã‚·ã«æ¥ç¶šã™ã‚‹OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
client = OpenAI(
    base_url="http://0.0.0.0:4000/v1", # litellm-proxy-base url
    api_key=GEMINI_API_KEY
)

def chat_with_model(
    prompt: str,
    model: str = "gemini-2.0-flash"
) -> str:
    """
    AIãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã‚’ã™ã‚‹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
    LiteLLMãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨
    
    Args:
        prompt: ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå›ç­”
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ å¿œç­”ã‚’ç”Ÿæˆä¸­...")
    
    try:
        # Geminiãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        if response and hasattr(response, 'choices') and len(response.choices) > 0:
            text_response = response.choices[0].message.content
            print(f"\nğŸ“ å›ç­”:\n{text_response}")
            return text_response
            
        print("âŒ å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return ""

def analyze_image(
    image_path: str,
    prompt: str = "ã“ã‚Œã¯ãªã‚“ã®ç”»åƒã§ã™ã‹",
    model: str = "gemini-2.0-flash"
) -> str:
    """
    ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹
    LiteLLMãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨
    
    Args:
        image_path: åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
        prompt: ç”»åƒã«é–¢ã™ã‚‹è³ªå•ã‚„æŒ‡ç¤º
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå›ç­”
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ–¼ï¸ ç”»åƒ: {image_path}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ ç”»åƒã‚’åˆ†æä¸­...")
    
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§Base64ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_base64 = encode_image_to_base64(image_path)
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text", 
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ]
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        if response and hasattr(response, 'choices') and len(response.choices) > 0:
            text_response = response.choices[0].message.content
            print(f"\nğŸ“ å›ç­”:\n{text_response}")
            return text_response
            
        print("âŒ å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return ""

def transcribe_audio(
    audio_path: str,
    language: str = "ja",
    model: str = "gemini-2.0-flash"
) -> str:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹ï¼ˆéŸ³å£°èªè­˜ï¼‰
    LiteLLMãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨
    
    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        language: éŸ³å£°ã®è¨€èªã‚³ãƒ¼ãƒ‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    print(f"ğŸ¤ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {audio_path}")
    print(f"ğŸŒ è¨€èª: {language}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ éŸ³å£°ã‚’èªè­˜ä¸­...")
    
    try:
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        with open(audio_path, "rb") as audio_file:
            audio_bytes = audio_file.read()
        audio_base64 = base64.b64encode(audio_bytes).decode("utf-8")
        
        # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"ã“ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚è¨€èª: {language}"
                        },
                        {
                            "type": "audio_url",
                            "audio_url": {
                                "url": f"data:audio/wav;base64,{audio_base64}"
                            }
                        }
                    ]
                }
            ]
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        if response and hasattr(response, 'choices') and len(response.choices) > 0:
            text_response = response.choices[0].message.content
            print(f"\nğŸ“ æ–‡å­—èµ·ã“ã—çµæœ:\n{text_response}")
            return text_response
            
        print("âŒ å¿œç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # Whisperãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã™
        try:
            print("ğŸ”„ Whisperãƒ¢ãƒ‡ãƒ«ã§ã®éŸ³å£°èªè­˜ã‚’è©¦ã—ã¾ã™...")
            # OpenAIäº’æ›ã®Whisper APIã‚’ä½¿ç”¨
            audio_file = open(audio_path, "rb")
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language=language
            )
            text_response = transcript.text
            print(f"\nğŸ“ æ–‡å­—èµ·ã“ã—çµæœ (Whisper):\n{text_response}")
            return text_response
        except Exception as whisper_e:
            print(f"âŒ Whisperã§ã®ã‚¨ãƒ©ãƒ¼: {str(whisper_e)}")
            return ""
        return ""

def generate_image(
    prompt: str, 
    output_path: str = "generated_images/generated_image.png",
    model: str = "gemini-2.0-flash-exp-image-generation"
) -> str:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦ç”»åƒã‚’ç”Ÿæˆã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ä¿å­˜ã™ã‚‹
    LiteLLMãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ï¼ˆæ³¨ï¼šç”»åƒç”Ÿæˆã¯ãƒ—ãƒ­ã‚­ã‚·ãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å ´åˆã€
    Gemini APIã‚’ç›´æ¥å‘¼ã³å‡ºã™ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ï¼‰
    
    Args:
        prompt: ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        output_path: ç”Ÿæˆã—ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‘ã‚¹
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ ç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    try:
        # ã¾ãšLiteLLMãƒ—ãƒ­ã‚­ã‚·çµŒç”±ã§ç”»åƒç”Ÿæˆã‚’è©¦ã¿ã‚‹
        try:
            response = client.images.generate(
                model=model,
                prompt=prompt,
                n=1,
                size="1024x1024"
            )
            
            if response and hasattr(response, 'data') and len(response.data) > 0:
                # ç”»åƒURLã¾ãŸã¯Base64ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                image_data = response.data[0]
                if hasattr(image_data, 'url') and image_data.url:
                    # URLã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    img_response = requests.get(image_data.url)
                    img_response.raise_for_status()
                    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                    os.makedirs(os.path.dirname(output_path), exist_ok=True)
                    # ç”»åƒã‚’ä¿å­˜
                    with open(output_path, "wb") as f:
                        f.write(img_response.content)
                    print(f"âœ… ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                    return output_path
                elif hasattr(image_data, 'b64_json') and image_data.b64_json:
                    # Base64ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’ä¿å­˜
                    img_data = base64.b64decode(image_data.b64_json)
                    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                    os.makedirs(os.path.dirname(output_path), exist_ok=True)
                    # ç”»åƒã‚’ä¿å­˜
                    with open(output_path, "wb") as f:
                        f.write(img_data)
                    print(f"âœ… ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                    return output_path
            
        except Exception as proxy_e:
            print(f"âš ï¸ LiteLLMãƒ—ãƒ­ã‚­ã‚·ã§ã®ã‚¨ãƒ©ãƒ¼: {str(proxy_e)}ã€‚ç›´æ¥APIã‚’å‘¼ã³å‡ºã—ã¾ã™...")
        
        # ä»¥ä¸‹ã¯ç›´æ¥Gemini APIã‚’å‘¼ã³å‡ºã™ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰
        # Gemini APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"
        url = f"{GEMINI_API_BASE}/{model}:generateContent?key={GEMINI_API_KEY}"
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        headers = {
            "Content-Type": "application/json"
        }
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡ - Gemini ç”»åƒç”Ÿæˆç”¨ã®æ­£ã—ã„å½¢å¼
        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }],
            "generationConfig": {
                "temperature": 0.4,
                "top_p": 1,
                "top_k": 32,
                "responseModalities": ["TEXT", "IMAGE"]
            }
        }
        
        # APIå‘¼ã³å‡ºã—
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "inlineData" in part and part["inlineData"]["mimeType"].startswith("image/"):
                        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
                        image_data = base64.b64decode(part["inlineData"]["data"])
                        
                        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                        os.makedirs(os.path.dirname(output_path), exist_ok=True)
                        
                        # ç”»åƒã‚’ä¿å­˜
                        with open(output_path, "wb") as f:
                            f.write(image_data)
                        
                        print(f"âœ… ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                        return output_path
        
        # æœ€æ–°ã®Imagen APIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†æ–¹æ³•ã‚’è©¦ã™
        try:
            imagen_url = "https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-flash:generateContent?key=" + GEMINI_API_KEY
            
            imagen_payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }]
            }
            
            imagen_response = requests.post(imagen_url, headers=headers, json=imagen_payload)
            imagen_response.raise_for_status()
            
            imagen_result = imagen_response.json()
            
            # ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãƒ­ã‚¸ãƒƒã‚¯
            if "candidates" in imagen_result and len(imagen_result["candidates"]) > 0:
                candidate = imagen_result["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    for part in candidate["content"]["parts"]:
                        if "inlineData" in part and part["inlineData"]["mimeType"].startswith("image/"):
                            image_data = base64.b64decode(part["inlineData"]["data"])
                            os.makedirs(os.path.dirname(output_path), exist_ok=True)
                            with open(output_path, "wb") as f:
                                f.write(image_data)
                            print(f"âœ… Imagen APIã§ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                            return output_path
            
            print("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return ""
            
        except Exception as alt_e:
            print(f"âŒ Imagen APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(alt_e)}")
            if hasattr(alt_e, 'response') and hasattr(alt_e.response, 'text'):
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {alt_e.response.text}")
            return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def encode_image_to_base64(image_path: str) -> str:
    """
    ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
    """
    # æ‹¡å¼µå­ã‹ã‚‰MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬
    _, ext = os.path.splitext(image_path.lower())
    
    try:
        # ç”»åƒã‚’ãƒã‚¤ãƒŠãƒªã§èª­ã¿è¾¼ã‚€
        with open(image_path, "rb") as img_file:
            img_data = img_file.read()
            
        # æ‹¡å¼µå­ã‹ã‚‰MIMEã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
        mime_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp'
        }
        mime_type = mime_map.get(ext, 'image/jpeg')
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        return base64.b64encode(img_data).decode('utf-8')
        
    except Exception as e:
        print(f"âŒ ç”»åƒã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return ""

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æã—ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œã™ã‚‹"""
    parser = argparse.ArgumentParser(description="Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (LiteLLMä½¿ç”¨): ç”»åƒç”Ÿæˆã€ãƒãƒ£ãƒƒãƒˆã€éŸ³å£°èªè­˜ãªã©ã®æ©Ÿèƒ½ã‚’æä¾›")
    subparsers = parser.add_subparsers(dest="command", help="ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰")

    # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆã‚³ãƒãƒ³ãƒ‰
    chat_parser = subparsers.add_parser("chat", help="ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆ")
    chat_parser.add_argument("prompt", help="ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    chat_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")
    
    # ç”»åƒèªè­˜ã‚³ãƒãƒ³ãƒ‰
    vision_parser = subparsers.add_parser("vision", help="ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ")
    vision_parser.add_argument("image", help="åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹")
    vision_parser.add_argument("-p", "--prompt", help="ç”»åƒã«é–¢ã™ã‚‹è³ªå•ã‚„æŒ‡ç¤º", default="ã“ã‚Œã¯ãªã‚“ã®ç”»åƒã§ã™ã‹")
    vision_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")
    
    # éŸ³å£°èªè­˜ã‚³ãƒãƒ³ãƒ‰
    speech_parser = subparsers.add_parser("speech", help="éŸ³å£°èªè­˜")
    speech_parser.add_argument("audio", help="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    speech_parser.add_argument("-l", "--language", help="è¨€èªã‚³ãƒ¼ãƒ‰", default="ja")
    speech_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")

    # ç”»åƒç”Ÿæˆã‚³ãƒãƒ³ãƒ‰
    image_parser = subparsers.add_parser("image", help="ç”»åƒã‚’ç”Ÿæˆ")
    image_parser.add_argument("prompt", help="ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    image_parser.add_argument("-o", "--output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", default="generated_images/generated_image.png")
    image_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash-exp-image-generation")
    
    args = parser.parse_args()
    
    # ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã«åŸºã¥ã„ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œ
    if args.command == "chat":
        chat_with_model(args.prompt, args.model)
    elif args.command == "vision":
        analyze_image(args.image, args.prompt, args.model)
    elif args.command == "speech":
        transcribe_audio(args.audio, args.language, args.model)
    elif args.command == "image":
        generate_image(args.prompt, args.output, args.model)
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()