#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éŸ³å£°åˆæˆï¼ˆTTSï¼‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ (çµ±åˆç‰ˆ)
OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¾ãŸã¯requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦LiteLLM Proxyã®OpenAIäº’æ›APIã‚’å‘¼ã³å‡ºã™
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆopenai/requestsï¼‰ã‚’é¸æŠã§ãã¾ã™
"""

import os
import sys
import json
import argparse
import requests
import time
from pathlib import Path
from typing import Optional, Dict, Any, Union

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (optional)
try:
    from openai import OpenAI
    OPENAI_CLIENT_AVAILABLE = True
except ImportError:
    OPENAI_CLIENT_AVAILABLE = False
    print("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚requestsãƒ¢ãƒ¼ãƒ‰ã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™ã€‚")

# LiteLLM Proxy APIã®ãƒ™ãƒ¼ã‚¹URL
BASE_URL = "http://0.0.0.0:4000/v1"

# APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹ã‹ã€ç©ºæ–‡å­—åˆ—ã‚’ä½¿ç”¨ï¼‰
API_KEY = os.environ.get("OPENAI_API_KEY", "")

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
output_dir = Path("./generated_audio")
output_dir.mkdir(exist_ok=True)

# TTS ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
model_name = "OpenAI/tts-1"  # æ¨™æº–ãƒ¢ãƒ‡ãƒ«
# model_name = "OpenAI/tts-1-hd"  # é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ï¼ˆã“ã¡ã‚‰ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼‰

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
openai_client = None
if OPENAI_CLIENT_AVAILABLE:
    openai_client = OpenAI(
        base_url=BASE_URL,
        api_key=API_KEY
    )

def generate_speech_with_openai(text: str, voice: str = "alloy", model: str = model_name, output_path: Optional[str] = None) -> str:
    """
    OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    
    Args:
        text: éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        voice: éŸ³å£°ã®ç¨®é¡ (alloy, echo, fable, onyx, nova, shimmer)
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (tts-1, tts-1-hd ãªã©)
        output_path: ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    if not OPENAI_CLIENT_AVAILABLE or openai_client is None:
        print("âŒ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚requestsãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
        return generate_speech_with_requests(text, voice, model, output_path)
    
    try:
        # ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        if output_path is None:
            timestamp = int(time.time())
            output_path = str(output_dir / f"speech_{voice}_{timestamp}.mp3")
        
        # éŸ³å£°ç”Ÿæˆ
        response = openai_client.audio.speech.create(
            model=model,
            voice=voice,
            input=text
        )
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
        response.stream_to_file(output_path)
        print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        print("â†ªï¸ requestsãƒ¢ãƒ¼ãƒ‰ã§å†è©¦è¡Œã—ã¾ã™")
        return generate_speech_with_requests(text, voice, model, output_path)

def generate_speech_with_requests(text: str, voice: str = "alloy", model: str = model_name, output_path: Optional[str] = None) -> str:
    """
    requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
    
    Args:
        text: éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        voice: éŸ³å£°ã®ç¨®é¡ (alloy, echo, fable, onyx, nova, shimmer)
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (tts-1, tts-1-hd ãªã©)
        output_path: ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    try:
        # ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
        if output_path is None:
            timestamp = int(time.time())
            output_path = str(output_dir / f"speech_{voice}_{timestamp}.mp3")
        
        # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        endpoint = f"{BASE_URL}/audio/speech"
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        headers = {
            "Content-Type": "application/json"
        }
        
        # APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¿½åŠ 
        if API_KEY:
            headers["Authorization"] = f"Bearer {API_KEY}"
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡
        payload = {
            "model": model,
            "voice": voice,
            "input": text
        }
        
        # APIå‘¼ã³å‡ºã—
        response = requests.post(endpoint, headers=headers, json=payload)
        response.raise_for_status()
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ä¿å­˜
        with open(output_path, "wb") as f:
            f.write(response.content)
        
        print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def generate_speech(text: str, voice: str = "alloy", model: str = model_name, output_path: Optional[str] = None, client_type: str = "auto") -> str:
    """
    éŸ³å£°åˆæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
    
    Args:
        text: éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        voice: éŸ³å£°ã®ç¨®é¡ (alloy, echo, fable, onyx, nova, shimmer)
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (tts-1, tts-1-hd ãªã©)
        output_path: ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
        client_type: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆopenai/requests/autoï¼‰
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print(f"ğŸ”Š éŸ³å£°: {voice}")
    print(f"ğŸ”§ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ—: {client_type}")
    
    print("ğŸ”„ éŸ³å£°ç”Ÿæˆä¸­...")
    
    if client_type == "openai" and OPENAI_CLIENT_AVAILABLE:
        return generate_speech_with_openai(text, voice, model, output_path)
    elif client_type == "requests" or not OPENAI_CLIENT_AVAILABLE:
        return generate_speech_with_requests(text, voice, model, output_path)
    else:  # auto
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ãã‚Œã‚’ä½¿ç”¨ã€ãã†ã§ãªã‘ã‚Œã°requests
        if OPENAI_CLIENT_AVAILABLE:
            return generate_speech_with_openai(text, voice, model, output_path)
        else:
            return generate_speech_with_requests(text, voice, model, output_path)

def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼šã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æã—ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œ
    """
    parser = argparse.ArgumentParser(description='çµ±åˆéŸ³å£°åˆæˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ')
    parser.add_argument('text', help='éŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ')
    parser.add_argument('--voice', '-v', default="alloy", choices=["alloy", "echo", "fable", "onyx", "nova", "shimmer"], 
                       help='éŸ³å£°ã®ç¨®é¡ (alloy, echo, fable, onyx, nova, shimmer)')
    parser.add_argument('--model', '-m', default=model_name, help='ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å (tts-1, tts-1-hd ãªã©)')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (çœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆ)')
    parser.add_argument('--client', '-c', choices=['openai', 'requests', 'auto'], default='auto',
                       help='ä½¿ç”¨ã™ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆopenai/requests/autoï¼‰')
    
    args = parser.parse_args()
    
    generate_speech(args.text, args.voice, args.model, args.output, args.client)

if __name__ == "__main__":
    main()