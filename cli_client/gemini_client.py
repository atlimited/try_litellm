#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Gemini ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
Gemini API ã‚’ç›´æ¥å‘¼ã³å‡ºã™ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
"""

import os
import argparse
import json
import sys
import base64
from typing import Optional, List, Dict, Any, Union
import requests
from PIL import Image
import io
import time
import wave
from pathlib import Path

# Gemini APIã‚­ãƒ¼
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "")

# Gemini API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
GEMINI_API_BASE = "https://generativelanguage.googleapis.com/v1beta/models"

def chat_with_model(
    prompt: str,
    model: str = "gemini-2.0-flash"
) -> str:
    """
    AIãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆã‚’ã™ã‚‹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
    Gemini APIã‚’ç›´æ¥å‘¼ã³å‡ºã™
    
    Args:
        prompt: ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå›ç­”
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ å¿œç­”ã‚’ç”Ÿæˆä¸­...")
    
    # Geminiãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    model_name = model.replace("Google/", "")
    
    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆAPIã‚­ãƒ¼ã‚’ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è¿½åŠ ï¼‰
    url = f"{GEMINI_API_BASE}/{model_name}:generateContent?key={GEMINI_API_KEY}"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json"
    }
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡
    payload = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }]
    }
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã‚’æŠ½å‡º
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        text_response = part["text"]
                        print(f"\nğŸ“ å›ç­”:\n{text_response}")
                        return text_response
        
        print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result}")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def generate_image(
    prompt: str, 
    output_path: str = "generated_images/generated_image.png",
    model: str = "gemini-2.0-flash-exp-image-generation"
) -> str:
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦ç”»åƒã‚’ç”Ÿæˆã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«ä¿å­˜ã™ã‚‹
    Gemini APIã‚’ç›´æ¥å‘¼ã³å‡ºã™
    
    Args:
        prompt: ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        output_path: ç”Ÿæˆã—ãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‘ã‚¹
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ ç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    # Geminiãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–ï¼ˆGoogle/ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãŒã‚ã‚Œã°å‰Šé™¤ï¼‰
    model_name = model.replace("Google/", "")
    
    # Gemini APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    url = f"{GEMINI_API_BASE}/{model_name}:generateContent?key={GEMINI_API_KEY}"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json"
    }
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡ - Gemini ç”»åƒç”Ÿæˆç”¨ã®æ­£ã—ã„å½¢å¼
    payload = {
        "contents": [{
            "parts": [{
                "text": prompt
            }]
        }],
        "generationConfig": {
            "temperature": 0.4,
            "top_p": 1,
            "top_k": 32,
            "responseModalities": ["TEXT", "IMAGE"]
        }
    }
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤º
        print(f"ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    # æ³¨æ„: JSONã‚­ãƒ¼åã¯ 'inline_data' ã§ã¯ãªã 'inlineData'
                    if "inlineData" in part and part["inlineData"]["mimeType"].startswith("image/"):
                        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
                        image_data = base64.b64decode(part["inlineData"]["data"])
                        
                        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
                        os.makedirs(os.path.dirname(output_path), exist_ok=True)
                        
                        # ç”»åƒã‚’ä¿å­˜
                        with open(output_path, "wb") as f:
                            f.write(image_data)
                        
                        print(f"âœ… ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                        return output_path
        
        # æœ€æ–°ã®Imagen APIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†æ–¹æ³•ã‚’è©¦ã™
        try:
            imagen_url = "https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-flash:generateContent?key=" + GEMINI_API_KEY
            
            imagen_payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }]
            }
            
            imagen_response = requests.post(imagen_url, headers=headers, json=imagen_payload)
            imagen_response.raise_for_status()
            
            imagen_result = imagen_response.json()
            print(f"ğŸ“Š Imagen APIãƒ¬ã‚¹ãƒãƒ³ã‚¹: {json.dumps(imagen_result, indent=2, ensure_ascii=False)}")
            
            # ç”»åƒãƒ‡ãƒ¼ã‚¿å–å¾—ã®ãƒ­ã‚¸ãƒƒã‚¯
            if "candidates" in imagen_result and len(imagen_result["candidates"]) > 0:
                candidate = imagen_result["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    for part in candidate["content"]["parts"]:
                        # æ³¨æ„: JSONã‚­ãƒ¼åã¯ 'inline_data' ã§ã¯ãªã 'inlineData'
                        if "inlineData" in part and part["inlineData"]["mimeType"].startswith("image/"):
                            image_data = base64.b64decode(part["inlineData"]["data"])
                            os.makedirs(os.path.dirname(output_path), exist_ok=True)
                            with open(output_path, "wb") as f:
                                f.write(image_data)
                            print(f"âœ… Imagen APIã§ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                            return output_path
            
            print("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return ""
            
        except Exception as alt_e:
            print(f"âŒ Imagen APIå‘¼ã³å‡ºã—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(alt_e)}")
            if hasattr(alt_e, 'response') and hasattr(alt_e.response, 'text'):
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {alt_e.response.text}")
            return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {json.dumps(payload, indent=2, ensure_ascii=False)}")
        return ""

def get_base64_encoded_image(image_path: str) -> str:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸæ–‡å­—åˆ—ã‚’è¿”ã™
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
    """
    with open(image_path, "rb") as img_file:
        img_data = img_file.read()
        
        # MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨æ¸¬
        ext = os.path.splitext(image_path)[1].lower()
        mime_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp'
        }
        mime_type = mime_map.get(ext, 'image/jpeg')
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        return base64.b64encode(img_data).decode('utf-8')

def analyze_image(
    image_path: str,
    prompt: str = "ã“ã‚Œã¯ãªã‚“ã®ç”»åƒã§ã™ã‹",
    model: str = "gemini-2.0-flash"
) -> str:
    """
    ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹
    Gemini APIã‚’ç›´æ¥å‘¼ã³å‡ºã™
    
    Args:
        image_path: åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
        prompt: ç”»åƒã«é–¢ã™ã‚‹è³ªå•ã‚„æŒ‡ç¤º
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå›ç­”
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ–¼ï¸ ç”»åƒ: {image_path}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ ç”»åƒã‚’åˆ†æä¸­...")
    
    # Geminiãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    model_name = model.replace("Google/", "")
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    image_base64 = get_base64_encoded_image(image_path)
    
    # ç”»åƒã®MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
    ext = os.path.splitext(image_path)[1].lower()
    mime_map = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.bmp': 'image/bmp',
        '.webp': 'image/webp'
    }
    mime_type = mime_map.get(ext, 'image/jpeg')
    
    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆAPIã‚­ãƒ¼ã‚’ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è¿½åŠ ï¼‰
    url = f"{GEMINI_API_BASE}/{model_name}:generateContent?key={GEMINI_API_KEY}"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json"
    }
    
    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡
    payload = {
        "contents": [{
            "parts": [
                {
                    "text": prompt
                },
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": image_base64
                    }
                }
            ]
        }]
    }
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã‚’æŠ½å‡º
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        text_response = part["text"]
                        print(f"\nğŸ“ å›ç­”:\n{text_response}")
                        return text_response
        
        print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result}")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""


def transcribe_audio(
    audio_path: str,
    language: str = "ja",
    model: str = "gemini-2.0-flash"
) -> str:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ï¼ˆéŸ³å£°èªè­˜ï¼‰
    Gemini APIã‚’ç›´æ¥å‘¼ã³å‡ºã™
    
    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        language: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆja, en, zh ãªã©ï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        éŸ³å£°ã‹ã‚‰èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    """
    print(f"ğŸ¤ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {audio_path}")
    print(f"ğŸŒ è¨€èª: {language}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ éŸ³å£°ã‚’èªè­˜ä¸­...")
    
    # Geminiãƒ¢ãƒ‡ãƒ«åã‚’æ­£è¦åŒ–
    model_name = model.replace("Google/", "")
    
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    with open(audio_path, "rb") as audio_file:
        audio_data = audio_file.read()
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
    
    # éŸ³å£°ã®MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
    ext = os.path.splitext(audio_path)[1].lower()
    mime_map = {
        '.mp3': 'audio/mpeg',
        '.wav': 'audio/wav',
        '.m4a': 'audio/m4a',
        '.ogg': 'audio/ogg',
        '.flac': 'audio/flac',
    }
    mime_type = mime_map.get(ext, 'audio/mpeg')
    
    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆAPIã‚­ãƒ¼ã‚’ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è¿½åŠ ï¼‰
    url = f"{GEMINI_API_BASE}/{model_name}:generateContent?key={GEMINI_API_KEY}"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    headers = {
        "Content-Type": "application/json"
    }
    
    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡ï¼ˆéŸ³å£°ï¼‰
    payload = {
        "contents": [{
            "parts": [
                {
                    "text": f"ã“ã®éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚è¨€èªã¯{language}ã§ã™ã€‚"
                },
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": audio_base64
                    }
                }
            ]
        }]
    }
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ã‚’æŠ½å‡º
        if "candidates" in result and len(result["candidates"]) > 0:
            candidate = result["candidates"][0]
            if "content" in candidate and "parts" in candidate["content"]:
                for part in candidate["content"]["parts"]:
                    if "text" in part:
                        text_response = part["text"]
                        print(f"\nğŸ“ èªè­˜çµæœ:\n{text_response}")
                        return text_response
        
        print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆå›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {result}")
        return ""
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’è§£æã—ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œã™ã‚‹"""
    parser = argparse.ArgumentParser(description="Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ: ç”»åƒç”Ÿæˆã€ãƒãƒ£ãƒƒãƒˆã€éŸ³å£°èªè­˜ãªã©ã®æ©Ÿèƒ½ã‚’æä¾›")
    subparsers = parser.add_subparsers(dest="command", help="ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰")

    # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆã‚³ãƒãƒ³ãƒ‰
    chat_parser = subparsers.add_parser("chat", help="ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆ")
    chat_parser.add_argument("prompt", help="ãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    chat_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="gemini-2.0-flash")
    
    # ç”»åƒç”Ÿæˆã‚³ãƒãƒ³ãƒ‰
    image_parser = subparsers.add_parser("image", help="ç”»åƒã‚’ç”Ÿæˆ")
    image_parser.add_argument("prompt", help="ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    image_parser.add_argument("-o", "--output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", default="generated_images/generated_image.png")
    image_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="gemini-2.0-flash-exp-image-generation")
    
    # ç”»åƒèªè­˜ã‚³ãƒãƒ³ãƒ‰
    vision_parser = subparsers.add_parser("vision", help="ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ")
    vision_parser.add_argument("image", help="åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹")
    vision_parser.add_argument("-p", "--prompt", help="ç”»åƒã«é–¢ã™ã‚‹è³ªå•ã‚„æŒ‡ç¤º", default="ã“ã‚Œã¯ãªã‚“ã®ç”»åƒã§ã™ã‹")
    vision_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="gemini-2.0-flash")
    
    # éŸ³å£°èªè­˜ã‚³ãƒãƒ³ãƒ‰
    speech_parser = subparsers.add_parser("speech", help="éŸ³å£°èªè­˜")
    speech_parser.add_argument("audio", help="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    speech_parser.add_argument("-l", "--language", help="è¨€èªã‚³ãƒ¼ãƒ‰", default="ja")
    speech_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="gemini-2.0-flash")
    
    args = parser.parse_args()
    
    # ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã«åŸºã¥ã„ã¦æ©Ÿèƒ½ã‚’å®Ÿè¡Œ
    if args.command == "image":
        generate_image(args.prompt, args.output, args.model)
    elif args.command == "vision":
        analyze_image(args.image, args.prompt, args.model)
    elif args.command == "chat":
        chat_with_model(args.prompt, args.model)
    elif args.command == "speech":
        transcribe_audio(args.audio, args.language, args.model)
    else:
        parser.print_help()
        sys.exit(1)

if __name__ == "__main__":
    main()