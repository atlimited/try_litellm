#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Gemini ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
LiteLLM ãƒ—ãƒ­ã‚­ã‚·ã‚’é€šã˜ã¦ Gemini API ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
"""

import os
import argparse
import json
import sys
import base64
from typing import Optional, List, Dict, Any, Union
import requests
from PIL import Image
import io

# LiteLLM ãƒ—ãƒ­ã‚­ã‚·ã® URL
LITELLM_PROXY_URL = "http://localhost:4000/v1"

def generate_image(
    prompt: str, 
    output_path: Optional[str],
    model: str = "gemini-2.0-flash-exp-image-generation"
) -> str:
    """
    Gemini ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        prompt: ç”»åƒç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        output_path: ç”Ÿæˆã•ã‚ŒãŸç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‘ã‚¹ï¼ˆçœç•¥å¯èƒ½ï¼‰
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹ã€ã¾ãŸã¯å‡ºåŠ›ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ ç”»åƒã‚’ç”Ÿæˆä¸­...")
    
    # Geminiã®ç”»åƒç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ§‹ç¯‰
    url = f"{LITELLM_PROXY_URL}/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
    }
    
    # Geminiã§ã¯ modalities ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "modalities": ["image", "text"],  # ç”»åƒã¨æ–‡å­—ä¸¡æ–¹ã®æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        print(f"ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ : {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆbase64å½¢å¼ï¼‰
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            if content.startswith("data:image"):
                # "data:image/png;base64," ãªã©ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
                image_data = content.split(",", 1)[1]
                
                if output_path:
                    # Base64ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    img_data = base64.b64decode(image_data)
                    with open(output_path, "wb") as f:
                        f.write(img_data)
                    print(f"âœ… ç”»åƒã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
                    return output_path
                else:
                    # å‡ºåŠ›ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ Base64 ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                    return content
            else:
                print(f"âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {content}")
                return ""
        else:
            print(f"âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
            return ""
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def get_base64_encoded_image(image_path: str) -> str:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹
    
    Args:
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆMIMEã‚¿ã‚¤ãƒ—ä»˜ãï¼‰
    """
    mime_map = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp',
    }
    
    extension = os.path.splitext(image_path)[1].lower()
    mime_type = mime_map.get(extension, 'image/jpeg')
    
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
    
    return f"data:{mime_type};base64,{encoded_string}"

def generate_response_with_image(
    prompt: str,
    image_path: str,
    model: str = "gemini/gemini-2.0-flash"
) -> str:
    """
    ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦ Gemini ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã™ã‚‹
    
    Args:
        prompt: ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        Gemini ã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ–¼ï¸ ç”»åƒ: {image_path}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ å¿œç­”ã‚’ç”Ÿæˆä¸­...")
    
    # ç”»åƒã‚’ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    base64_image = get_base64_encoded_image(image_path)
    
    # Gemini ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹ãŒé…åˆ—ã«ãªã‚‹ç‚¹ã«æ³¨æ„ï¼‰
    url = f"{LITELLM_PROXY_URL}/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
    }
    
    # Gemini ã§ã¯ LiteLLM ã‚’é€šã—ã¦ä»¥ä¸‹ã®ã‚ˆã†ãªå½¢å¼ã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": base64_image
                        }
                    }
                ]
            }
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…¨ä½“ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        # print(f"ğŸ“Š ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ : {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            print(f"\nğŸ“ å›ç­”:\n{content}")
            return content
        else:
            print(f"âŒ å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
            return ""
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def chat_with_gemini(
    prompt: str,
    model: str = "gemini/gemini-2.0-flash"
) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ Gemini ã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹
    
    Args:
        prompt: ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        
    Returns:
        Gemini ã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
    """
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {model}")
    print("ğŸ”„ å¿œç­”ã‚’ç”Ÿæˆä¸­...")
    
    # Gemini ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ§‹ç¯‰
    url = f"{LITELLM_PROXY_URL}/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
    }
    
    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": prompt
            }
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            print(f"\nğŸ“ å›ç­”:\n{content}")
            return content
        else:
            print(f"âŒ å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {result}")
            return ""
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        if hasattr(e, 'response') and hasattr(e.response, 'text'):
            print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {e.response.text}")
        return ""

def main():
    parser = argparse.ArgumentParser(description="Gemini ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ")
    subparsers = parser.add_subparsers(dest="command", help="å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰")
    
    # ç”»åƒç”Ÿæˆã‚³ãƒãƒ³ãƒ‰
    image_parser = subparsers.add_parser("image", help="ç”»åƒã‚’ç”Ÿæˆ")
    image_parser.add_argument("prompt", help="ç”»åƒç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    image_parser.add_argument("-o", "--output", help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹", default="generated_images/generated_image.png")
    image_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")
    
    # ç”»åƒèªè­˜ã‚³ãƒãƒ³ãƒ‰
    vision_parser = subparsers.add_parser("vision", help="ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆ")
    vision_parser.add_argument("prompt", help="ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    vision_parser.add_argument("image", help="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹")
    vision_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒƒãƒˆã‚³ãƒãƒ³ãƒ‰
    chat_parser = subparsers.add_parser("chat", help="ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ãƒãƒ£ãƒƒãƒˆ")
    chat_parser.add_argument("prompt", help="ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    chat_parser.add_argument("-m", "--model", help="ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«", default="Google/gemini-2.0-flash")
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹
    args = parser.parse_args()
    
    if args.command == "image":
        generate_image(args.prompt, args.output, args.model)
    elif args.command == "vision":
        generate_response_with_image(args.prompt, args.image, args.model)
    elif args.command == "chat":
        chat_with_gemini(args.prompt, args.model)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
